{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6FeE3Xgtqf46","outputId":"02a43de9-c4ed-4b98-8ce7-6520b465d7e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n"]}],"source":["!pip install \"numpy<2.0\"\n","import os\n","os.kill(os.getpid(), 9)  # Force restart the runtime after install\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25691,"status":"ok","timestamp":1752345607195,"user":{"displayName":"Akshit Soji","userId":"09947785027529173767"},"user_tz":-330},"id":"D9koZjXKR9Yd","outputId":"2e03919c-6dc6-40f6-e6bc-d1afa906bcd5"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["✅ Loaded 5 multi-document samples.\n"]}],"source":["# Install correct versions of datasets and fsspec\n","!pip install -q datasets==2.14.0 fsspec==2023.6.0\n","\n","from datasets import load_dataset\n","\n","# Load a small subset (100 samples) from CNN/DailyMail for quick testing\n","dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"test[:50]\")\n","\n","multidoc_test = []\n","for i in range(0, 50, 10):\n","    docs = \" \".join(dataset[i + j][\"article\"] for j in range(10))\n","    summary = dataset[i][\"highlights\"]\n","    multidoc_test.append({\"documents\": docs, \"summary\": summary})\n","\n","print(f\"✅ Loaded {len(multidoc_test)} multi-document samples.\")\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uV9F47n0kBm-","executionInfo":{"status":"ok","timestamp":1752346332190,"user_tz":-330,"elapsed":685090,"user":{"displayName":"Akshit Soji","userId":"09947785027529173767"}},"outputId":"c1757071-b8a8-44da-db88-d2bfd3b76a9e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-multi_news and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["✅ Done! Generated 5 summaries.\n"]}],"source":["from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n","import torch\n","\n","# Load PEGASUS model and tokenizer\n","model_name = \"google/pegasus-multi_news\"\n","tokenizer = PegasusTokenizer.from_pretrained(model_name)\n","model = PegasusForConditionalGeneration.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Generate summaries\n","generated_summaries = []\n","\n","for item in multidoc_test:\n","    inputs = tokenizer(\n","        item[\"documents\"],\n","        return_tensors=\"pt\",\n","        padding=True,\n","        truncation=True,\n","        max_length=1024,\n","    ).to(model.device)\n","\n","    summary_ids = model.generate(\n","        **inputs,\n","        num_beams=4,\n","        max_length=256,\n","        min_length=32,\n","        length_penalty=2.0,\n","        early_stopping=True,\n","    )\n","\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    generated_summaries.append({\n","        \"reference\": item[\"summary\"],\n","        \"generated\": summary\n","    })\n","\n","print(\"✅ Done! Generated\", len(generated_summaries), \"summaries.\")\n"]},{"cell_type":"code","source":["# STEP 3: Evaluate ROUGE Scores\n","\n","from rouge_score import rouge_scorer\n","import time\n","\n","scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rouge2\", \"rougeL\"], use_stemmer=True)\n","\n","rouge1_scores, rouge2_scores, rougeL_scores = [], [], []\n","start_time = time.time()\n","\n","for sample in generated_summaries:\n","    scores = scorer.score(sample[\"reference\"], sample[\"generated\"])\n","    rouge1_scores.append(scores[\"rouge1\"].fmeasure)\n","    rouge2_scores.append(scores[\"rouge2\"].fmeasure)\n","    rougeL_scores.append(scores[\"rougeL\"].fmeasure)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","avg_time_per_sample = elapsed_time / len(generated_summaries)\n","\n","# Final averaged scores\n","print(\"📊 ROUGE Evaluation on\", len(generated_summaries), \"samples\")\n","print(f\"ROUGE-1: {sum(rouge1_scores) / len(rouge1_scores):.4f}\")\n","print(f\"ROUGE-2: {sum(rouge2_scores) / len(rouge2_scores):.4f}\")\n","print(f\"ROUGE-L: {sum(rougeL_scores) / len(rougeL_scores):.4f}\")\n","print(f\"\\n⏱️ Avg time per sample: {avg_time_per_sample:.2f} sec\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vkx-OLSyVAH","executionInfo":{"status":"ok","timestamp":1752346457364,"user_tz":-330,"elapsed":52,"user":{"displayName":"Akshit Soji","userId":"09947785027529173767"}},"outputId":"b49711c3-c063-43b1-d3b8-e72e6b30d88a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["📊 ROUGE Evaluation on 5 samples\n","ROUGE-1: 0.1748\n","ROUGE-2: 0.0556\n","ROUGE-L: 0.1250\n","\n","⏱️ Avg time per sample: 0.01 sec\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"9Dqzfo_67u4_"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPG0hYG/GwDuVkK8KYF0JWq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}